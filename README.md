# `italian_latin_parallel`: An Italian-Latin Parallel Corpus (30,000 Sentences)

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.15530134.svg)](https://doi.org/10.5281/zenodo.15530134)

This dataset provides approximately 30,000 parallel sentences between **Italian and Latin**. It is designed for tasks such as machine translation and cross-linguistic research.

## Key Features

*   **Size:** ~30,000 translation pairs.
*   **Languages:** Italian (`it`), Latin (`la`).
*   **Source for Latin:** Derived from the `grosenthal/latin_english_parallel` dataset (Loeb Classical Library & Vulgate).
*   **Source for Italian:** Machine-translated from modernized English versions of the `grosenthal/latin_english_parallel` dataset.
*   **Format:** Single `train` split.

## Dataset Creation Process

The creation of this dataset involved a multi-step process:

1.  **Original Latin Source (`grosenthal/latin_english_parallel`):**
    *   The Latin texts were sourced from the `grosenthal/latin_english_parallel` dataset.
    *   Approximately 66% of these Latin texts originate from the Loeb Classical Library.
    *   Approximately 34% originate from the Vulgate translation.
    *   For Loeb Classical Library texts, alignment was performed manually between the original Latin (Source) and English (Target) sequences. The original Latin is not copyrighted.

2.  **English Modernization (Intermediate Step):**
    *   The English translations in the `grosenthal/latin_english_parallel` dataset were often outdated and copyrighted.
    *   To address this, these English texts were modernized and transformed into public domain versions using `gpt-3.5-turbo`.
    *   The prompt used for modernization was:
        ```
        Translate an old dataset from the 1800s to modern English while preserving the original meaning and exact same sentence structure. Retain extended adjectives, dependent clauses, and punctuation. Output the translation preceded by the text "Modern Translation: ". If a given translation is not a complete sentence, repeat the input sentence.
        ```
    *   These modernized English outputs were then manually corrected.

3.  **Italian Translation (This Dataset):**
    *   The Italian texts in *this* dataset (`Dddixyy/italian_latin_parallel`) were generated by machine translating the **modernized English texts** (from step 2) into Italian.
    *   **Translation Tool:** Google Translate was used for this English-to-Italian translation.

## Data Fields

Each entry in the dataset consists of the following fields:

*   `id` (string): A unique identifier for the sample.
*   `translation` (dict): A dictionary containing the language pair:
    *   `it` (string): The Italian text.
    *   `la` (string): The Latin text.
*   `index` (int): The original index from the source data.
*   `file` (string): The original file path from the `grosenthal/latin_english_parallel` dataset, often indicating the author and work (e.g., `vulgate/gen.txt`). This can be useful for contextual analysis.

**Example:**

```json
{
  "id": "0",
  "translation": {
    "it": "IN principio Dio creò il cielo e la terra.",
    "la": "IN PRINCIPIO creavit Deus caelum et terram."
  },
  "index": 0,
  "file": "vulgate/gen.txt"
}
```

## Data Splits

The dataset contains a single split:

*   `train`: 30,000 examples.

## Intended Uses

This dataset can be valuable for:

*   Training machine translation models for Italian-Latin and Latin-Italian.
*   Linguistic research on parallel corpora, particularly exploring translations between classical and modern Romance languages.
*   Developing cross-lingual information retrieval systems.
*   Computational stylometry or authorship attribution studies, leveraging the `file` field for source context.

## Limitations and Important Considerations

*   **Indirect Translation:** The Italian text is a translation of a *modernized English translation* of the original Latin, not a direct translation from Latin to Italian by the dataset creator. This introduces an intermediary language and an additional layer of machine translation, which may affect nuance and fidelity.
*   **Stylistic Nuances:** The original stylistic features of the Latin authors might be filtered or altered due to the two-step translation process (Latin -> Modernized English -> Italian).
*   **Machine Translation Quality:** The Italian texts were generated using Google Translate. While generally high quality, machine translation can introduce errors or awkward phrasing.
*   **Scope of Latin Texts:** The Latin texts are primarily from classical (Loeb) and biblical (Vulgate) sources, which may not represent all genres or periods of Latin literature.

## How to Use with `datasets`

You can easily load the dataset using the Hugging Face `datasets` library:

```python
from datasets import load_dataset

# Load the dataset
dataset = load_dataset("Dddixyy/italian_latin_parallel")

# Access an example from the train split
print(dataset["train"][0])
# Output:
# {
#   'id': '0',
#   'translation': {'it': 'IN principio Dio creò il cielo e la terra.', 'la': 'IN PRINCIPIO creavit Deus caelum et terram.'},
#   'index': 0,
#   'file': 'vulgate/gen.txt'
# }
```

## Citation

If you use this dataset in your research, please cite both the original `latin_english_parallel` dataset and this derived work:

```bibtex
@misc{grosenthal_latin_english_parallel_2023,
  author = {Grosenthal, Gabriel},
  title = {latin_english_parallel},
  year = {2023},
  publisher = {Hugging Face},
  journal = {Hugging Face Hub},
  howpublished = {\url{https://huggingface.co/datasets/grosenthal/latin_english_parallel}}
}

@misc{brunori_italian_latin_parallel_2024,
  author = {Brunori, Davide},
  title = {italian_latin_parallel: An Italian-Latin Parallel Corpus Derived from Modernized English Translations},
  year = {2024},
  publisher = {Hugging Face},
  journal = {Hugging Face Hub},
  doi = {10.5281/zenodo.15530134},
  howpublished = {\url{https://huggingface.co/datasets/Dddixyy/italian_latin_parallel}}
}
```

# #DATASET info

```yaml
---
dataset_info:
  features:
  - name: latin
    dtype: string
  - name: italian
    dtype: string
  splits:
  - name: train
    num_bytes: 10395242 # This might need update if data fields change (e.g. adding 'id', 'index', 'file' separately)
    num_examples: 30000
  download_size: 7410973
  dataset_size: 10395242 # Same as num_bytes for train split here
configs:
- config_name: default
  data_files:
  - split: train
    path: data/train-* # Or the specific path to your Parquet/JSONL files
license: mit
task_categories:
- translation
language:
- la
- it
tags:
- translation
- parallel-corpus
- italian
- latin
- classical-languages
- romance-languages
pretty_name: "Italian-Latin Parallel Corpus"
annotations_creators:
- machine-generated # For the Italian part
- crowdsourced # If manual correction of English was extensive
- expert-generated # For original Latin/English alignments in source
source_datasets:
- grosenthal/latin_english_parallel
multilinguality: bilingual
---
```
